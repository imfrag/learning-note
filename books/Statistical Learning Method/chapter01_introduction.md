

# 统计学习方法（第二版）—— 李航（著）

----

# 第一章	统计学习及监督学习概论

## 1.1	统计学习

​	统计学习（Statistical Learning）是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析。

​	主要特点：

* 以计算机及网络为平台
* 以数据为研究对象
* 目的是对数据进行预测与分析

> 赫尔伯特 · 西蒙（Herbert A. Simon）曾对”学习“给出以下定义：如果一个系统能够通过执行某个过程改进它的性能，这就是学习。

​	统计学习的研究对象是数据。（统计学习关于数据的基本假设是同类数据具有一定的统计规律性）

​	

​	实现统计学习方法的基本步骤如下：

1. 获得一个有限的训练数据集合
2. 确定包含所有可能的模型的假设空间，即学习模型的集合
3. 确定模型选择的准则，即学习的策略
4. 实现求解最优模型的算法，即学习的算法
5. 通过学习方法选择最优模型
6. 利用学习的最优模型对新数据进行预测或分析



## 1.2	统计学习的分类

### 1.2.1	基本分类

​	统计学习或机器学习一般包括监督学习、无监督学习、强化学习。有时还包括半监督学习和主动学习。



#### 1. 监督学习（Supervised Learning）:warning:

​	监督学习是指从标注数据中学习预测模型的机器学习。其学习的本质是学习==输入到输出的映射的统计规律==。

​	（1）输入空间、特征空间和输出空间

​	将输入与输出所有可能取值的集合分别称为输入空间（Input Space）和输出空间（Output Space）。每个具体的输入时一个实例（Instance），通常由特征向量（feature vector）表示。所有特征向量存在的空间称为特征空间。

> 有时假设输入空间与特征空间为相同的空间，对他们不予区分。有时假设输入空间与特征空间为不同的空间，将实例从输入空间映射到特征空间。

> NOTE::x:
>
> 欧式空间，设 $V$是实数域$R$上的一个向量空间。如果对于$V$中任意一对向量$\xi$和$\eta$，有一个确定的记作$<\xi, \eta>$的实数与它们对应，叫作向量$\xi$与$\eta$的内积（或标量积），并且下列条件被满足：
>
> 1. $<\xi, \eta>$ = $<\eta, \xi>$
> 2. $<\xi + \zeta, \eta>$ = $<\xi, \eta>$ + $<\zeta, \eta>$
> 3. $<a\xi, \eta>$ = $a<\xi, \eta>$
> 4. $\xi \neq 0$，$<\xi, \xi> > 0$
>
> 这里$\xi, \eta, \zeta$是$V$的任意向量，$a$是任意实数，那么$V$叫作对这个内积来说的一个欧几里得（Euclid）空间（简称欧氏空间）

> 输入变量与输出变量均为连续变量的预测问题，称为回归问题；输出变量为有限个离散变量的预测问题，称为分类问题；输入变量与输出变量均为变量序列的预测问题，称为标注问题。

（2）联合概率分布

​	监督学习假设输入与输出的随机变量$X$和$Y$遵循联合概率分布$P(X, Y)$。

（3）假设空间

​	监督学习的目的在于学习一个由输入到输出的映射，这一映射由模型表示。模型属于由输入空间到输出空间的映射的集合，这个集合就是假设空间（hypothesis space）。



#### 2. 无监督学习（Unsupervised Learning）

​	无监督学习是指从无标注数据中学习预测模型的机器学习问题。其本质是学习数据中的==统计规律或潜在结构==。

> 在无监督学习中，每一个输出是对输入的分析结果，由输入的类别、转换和概率表示。模型可以实现对数据的聚类、降维和概率估计。

#### 3. 强化学习（Reinforcement Learning）:x:

​	强化学习是指智能系统在于环境连续互动中学习最优行为策略的机器学习问题。



#### 4. 半监督学习（semi-Supervised Learning）与主动学习（Active Learning）

​	半监督学习是指利用标注数据和未标注数据学习预测模型的机器学习问题。通常有少量标注数据和大量未标注数据。半监督学习旨在利用为标注数据中的信息，辅助标注数据。

​	主动学习是指机器不断主动给出实例让教师进行标注，然后利用标注数据学习预测模型的机器学习问题。主动学习的目标是找出对学习最有帮助的实例让教师标注，以较小的标注代价，达到较好的学习效果。



### 1.2.2 按模型分类

#### 1. 概率模型（probabilistic model）与非概率模型（non-probabilistic model）（或确定性模型（deterministic model））:warning:

​	在监督学习中，概率模型取条件概率分布形式$P(y|x)$；非概率模型取函数形式$y=f(x)$。

​	在非监督学习中，概率模型取条件概率分布形式$P(z|x)$或$P(x|z)$；非概率模型取函数形式$z=g(x)$。

> 概率模型，决策树、朴素贝叶斯、隐马尔科夫模型、条件随机场、概率潜在语义分析、潜在狄利克雷分配和高斯混合模型
>
> 非概率模型，感知机、支持向量机、k近邻、AdaBoost、k均值、潜在语义分析和神经网络
>
> 逻辑斯蒂回归即可看做是概率模型，又可看作是非概率模型

​	:question:条件概率分布$P(y|x)$和函数$y=f(x)$可以相互转化。具体地，条件概率分布最大化后得到函数，函数归一化后得到条件概率分布。概率模型和非概率模型的区别不在于输入与输出之间的映射关系，而是在于模型的内在结构。概率模型一定可以表示为联合概率分布的形式，其中的变量表示输入、输出、隐变量甚至参数。而针对非概率模型则不一定存在这样的联合概率分布。

​	:question:概率模型的代表是概率图模型（probabilistic graphical model），概率图模型是联合概率分布由有向图或无向图表示的概率模型，而联合概率分布可以根据图的结构分解为因子乘积形式。

> 贝叶斯网络、马尔科夫随机场、条件随机场是概率图模型

​	无论模型如何复杂，均可以用最基本的加法规则和乘法规则进行概率推理

> 加法规则：$P(x) = \sum_yP(x,y)$。乘法规则： $P(x, y) = P(x)P(y|x)$

#### 2. 线性模型（linear model）与非线性模型（non-linear model）

​	针对非概率模型，可以分为线性模型与非线性模型。区分的依据是函数$y=f(x)$是否为线性函数。

> 线性模型，感知机、线性支持向量机、k近邻、k均值、潜在语义分析
>
> 非线性模型，核函数支持向量机、AdaBoost、神经网络

#### 3. 参数化模型（parametric model）与非参数化模型（non-parametric model）

​	参数化模型假设模型参数的维度固定，模型可以由有限维参数完全刻画；非参数化模型假设模型参数的维度不固定或者说无穷大，随着训练数据量的增加而不断增大。



### 1.2.3 按算法分类

​	根据算法，可以分为在线学习（online learning）与批量学习（batch learning）

> 有些场景要求学习必须是在线的。比如，数据依次达到无法存储；数据规模很大，不可能一次处理所有数据；数据的模式随时间动态变化。



### 1.2.4 按技巧分类

#### 1. 贝叶斯学习（Bayesian learning）或贝叶斯推理（Bayesian inference）:warning:

​	其主要思想是，在概率模型的学习和推理中，利用贝叶斯定力，计算在给定条件下模型的条件概率，即后验概率，并应用这个原理进行模型的估计。将模型、为观测要素及其参数用变量表示，使用模型先验分布是贝叶斯学习的特点。

​	假设随机变量$D$表示数据，随机变量$\theta$表示模型参数。根据贝叶斯定理，后验概率$P(\theta|D)$：
$$
P(\theta|D) = \frac{P(\theta)P(D|\theta)}{P(D)}
$$
​	:question:其中$P(\theta)$是先验概率，$P(D|\theta)$是似然函数。

​	模型估计时，估计整个后验概率分布。如果需要给出一个模型，通常选择后验概率最大的模型。

​	:question:预测时，计算数据对后验概率分布的期望值（其中$x$是新样本）：
$$
P(x|D) = \int{P(x|\theta, D)P(\theta|D)d\theta}
$$
​	:question:贝叶斯估计与极大似然估计在思想上有很大的不同。极大似然估计：$\hat{\theta} = arg max_{\theta}P(D|\theta)$， 贝叶斯估计：$\hat{P}(\theta|D) = \frac{P(\theta)P(D|\theta)}{P(D)}$



#### 2. 核方法（kernel method）

​	核方法是使用核函数表示和学习非线性模型的一种机器学习方法。在一些线性模型的学习方法基于相似度计算，更具体的，向量内积计算。核方法可以把他们扩展到非线性模型的学习。

​	把线性模型扩展到非线性模型，直接的做法是显式地定义从输入空间（低维空间）到特征空间（高维空间）的映射，在特征空间中进行内积计算。而核方法的技巧在于不显示地定义这个映射，而是直接定义核函数，即映射之后在特征空间的内积。

​	假设$x_1$和$x_2$是输入空间的任意两个实例（向量），其内积是$\langle{x_1, x_2}\rangle$。假设从输入空间到特征空间的映射是$\phi$，于是$x_1$和$x_2$的特征空间的映像是$\phi{\left(x_1\right)}$和$\phi{\left(x_2\right)}$，其内积是$\langle{\phi(x_1), \phi(x_2)}\rangle$。核方法直接在输入空间中定义核函数$K(x_1, x_2)$，使其满足$K(x_1, x_2)=\langle{\phi(x_1), \phi(x_2)}\rangle$。



## 1.3 统计学习方法三要素

### 1.3.1	模型

​	模型，即所要学习的条件概率分布或决策函数。模型的假设空间（hypothesis space）包含所有可能的条件概率分布和决策函数。假设空间用$\cal F$表示。其可表示为：
$$
\cal F = \{f|Y=f(X)\}
$$
​	其中，$X$和$Y$是定义在输入空间$\cal X$和输出空间$\cal Y$上的变量。

​	通常$\cal F$是由一个参数向量决定的函数簇：
$$
\cal F = \{f|Y=f_\theta(X), \theta\in\bf{R^n}\}
$$
​	参数向量$\theta$取值于n维欧氏空间$\bf R^n$，称为参数空间（parameter space）。假设空间定义为条件概率同理。

### 1.3.2	策略

​	策略，即统计学习按照什么样的准则学习或者选择最优模型。

#### 	1. 损失函数（loss function）和风险函数（risk function）

​	损失函数是$f(X)$和$Y$的非负实值函数，记作$L(Y, f(X))$。

​	统计学常用的损失函数有：

​	（1） 0-1损失函数（0-1 loss function）
$$
L(Y, f(X)) = \begin{cases}
1, Y \neq f(X) \\
0, Y =f(X) \\
\end{cases}
$$
​	（2） 平方损失函数（quadratic loss function）
$$
L(Y, f(X))=(Y - f(X))^2
$$
​	（3） 绝对损失函数（absolute loss function）
$$
L(Y, f(X)) = |Y - f(X)|
$$
​	（4） 对数损失函数（logarithmic loss function）或对数似然损失函数（log-likelihood loss function）
$$
L(Y, f(X)) = - logP(Y|X)
$$
​	由于模型的输入、输出$(X, Y)$是随机变量，遵循联合分布$P(X, Y)$，所以损失函数的期望是
$$
R_{exp}(f) = E_P[L(Y, f(X))] \\
	= \int_{\cal X\times Y}{L(y, f(x))P(x, y)dxdy}
$$
​	这是理论上模型$f(X)$关于联合分布$P(X, Y)$的平均意义的损失，称为风险函数或期望损失（expected loss）。

​	模型$f(X)$关于训练数据集的平均损失称为经验风险（empirical risk）或经验损失（empirical loss），记作$R_{emp}$：
$$
R_{emp}(f) = {\frac{1}{N}}\sum^{N}_{i=1}L(y_i,f(x_i))
$$
​	:question:期望风险$R_{exp}$是模型关于联合分布的期望损失，经验风险$R_{emp}$是模型关于训练样本集的平均损失。根据大数定律，当样本容量$N$趋于无穷时，经验风险预期期望风险$R_{emp}\to R_{exp}$。所以一个很自然的想法是用经验风险估计期望风险。由于现实中的训练样本有限，甚至很小，所以用经验风险估计期望风险并不理想。这就关系到监督学习的两个基本策略：经验风险最小化和结构风险最小化。

#### 	2. 经验风险最小化（empirical risk minimization, ERM）和结构风险最小化（structural risk minimization, SRM）

​	经验风险最小化求解最优模型：
$$
{min_{f\in {\cal F}}}{\frac{1}{N}}L(y_i, f(x_i))
$$
​	当样本容量足够大时，经验风险最小化能够保证有很好的学习效果。:question:极大似然估计就是经验风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数是，经验风险最小化就等价于极大似然估计。

​	当样本容量很小时，经验风险最小化学习的效果就未必很好，会产生过拟合（over-fitting）现象

​	结构风险最小化是为了防止过拟合而提出的策略。结构风险最小化等价于正则化（regularization）。结构风险在经验风险上加上表示模型复杂度的正则化项（regularizer）或罚项（penalty term）：
$$
R_{srm}(f) = {\frac{1}{N}}{\sum^{N}_{i=1}L(y_i, f(x_i))} + \lambda{\cal J(f)}
$$
​	其中${\cal J(f)}$是模型的复杂度，是定义在假设空间$\cal F$上的泛函。$\lambda \geq 0$是系数，权衡经验风险和模型复杂度。

​	:question:贝叶斯估计中的最大后验概率估计（maximum posterior probability estimation, MAP）就是结构风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计。

### 1.3.3	算法

​	算法，指学习模型的具体计算方法。统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型。



## 1.4 模型评估与模型选择

### 1.4.1	训练误差（train error）与测试误差（test error）

​	:question:训练误差的大小，对判断给定的问题是不是一个容易学习的问题是有意义的，但本质上不重要。

### 1.4.2	过拟合与模型选择

​	当假设空间含有不同复杂度（例如，不同的参数个数）的模型时，就要面临模型选择（model selection）的问题。过拟合（over fitting），是指学习时选择的模型所包含的参数过多，以至出现这一模型对已知数据预测有较好的表现，但对未知数据预测的结果较差。

>:x:最小二乘法



## 1.5 正则化与交叉验证​（模型选择方法）​

### 1.5.1	正则化（regularization）

​	正则化是结构风险最小化策略的实现，在经验风险上加上一个正则化项（regularizer）或罚项（penalty term）。正则化项通常是模型复杂度的单调递增函数。正则化一般形式如下：
$$
min_{f \in \cal F}{\frac{1}{N}}\sum_{i=1}^{N}L(y_i, f(x_i)) + \lambda{\cal J}(f)
$$
​	其中，第一项是经验风险，第二项是正则化项，$\lambda \geq0$为调整两者之间关系的系数。

> :x:范数

> 奥卡姆剃刀（Occam‘s razor）原理，"如无必要，勿增实体"（Entities should not be multiplied unnecessarily）。

​	:question:从贝叶斯估计的角度来看，正则化项对应于模型的先验概率。

### 1.5.2	交叉验证（cross validation）

	1. 简单交叉验证
 	2. S折交叉验证（S-fold cross validation）
 	3. 留一交叉验证



## 1.6 泛化能力（generalization ability）

### 1.6.1	泛化误差

​	泛化能力，指学习到的模型对无知数据的预测能力。

​	如果学到的模型是$\hat f$，那么用这个模型对未知数据预测的误差，为泛化误差（generalization error）：
$$
R_{exp}(\hat f) = E_P[L(Y, \hat f(X))]\\
= \int_{\cal X \times Y}L(y, \hat f(x))P(x, y)dxdy
$$
​	:question:泛化误差就是所学习到的模型的期望风险

### 1.6.2	泛化误差上界:x:



## 1.7 生成模型与判别模型

​	模型的一般形式为决策函数$Y=f(X)$或者条件概率分布$P(Y|X)$。监督学习方法又可分为生成方法（generative approach）和判别方法（discriminative approach）。相应的模型分别为生成模型（generative model）和判别模型（discriminative model）。

​	生成方法由数据学习联合概率分布$P(X,Y)$，然后求出条件概率分布$P(Y|X)$作为预测的模型。

​	判别方法是数据直接学习决策函数$Y=f(X)$或条件概率分布$P(Y|X)$  



​	:question:生成方法特点：可以还原联合概率分布$P(X, Y)$，收敛速度较快，当样本容量增加时，学到的模型可以更快地收敛于真实模型；当存在隐变量时，然可以用生成方法学习。

​	:question:判别方法特点：直接面对预测，学习的准确率较高；由于直接学习决策函数或条件概率分布，可以对数据进行各种程度上的抽象、定义特征并使用特征，从而简化学习问题。



## 1.8 监督学习应用

### 1.8.1	分类问题（classification）:x:

​	评价分类器性能的指标一般是分类准确率（accuracy），即正确分类的样本数与总样本数之比。

​	对于二分类问题常用的评价指标是精确率（precision）与召回率（recall）。通常以关注的类为正类，其他类为负类，则：

​		TP——正 - 正 true

​		FN——正 - 负 false

​		FP——负 - 正 false

​		TN——负 - 负 true

​	精确率定义为：$P = \frac{TP}{TP+FP}$，召回率定义为：$R=\frac{TP}{TP+FN}$，$F_1$值，精确率和召回率的调和均值，即$\frac{2}{F_1}=\frac{1}{P}+\frac{1}{R}$或$F_1=\frac{2TP}{2TP+FP+FN}$。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        

### 1.8.2	标注问题（tagging）:x:

​	标注问题是分类问题的一个推广，标注问题又是更复杂的结构预测（structure prediction）问题的简单形式。标注问题的输入时一个观测序列，输出是一个标记序列或状态序列。标注问题的目标在于学习一个模型，使它能够对观测序列给出标记序列作为预测。

​	:question:标注问题在信息抽取、自然语言处理等领域被广泛应用。​

### 1.8.3	回归问题（regression）:x:

​	回归用于预测输入变量和输出变量的关系，特别是当输入变量发生变换时，输出变量也随之发生变化。（回归问题的学习等价于函数拟合）

​	:question:回归学习常用的损失函数是平方损失函数，在此情况下，回归问题可以用最小二乘法求解。​